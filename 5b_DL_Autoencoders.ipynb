{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI 470 Activities and Case Studies\n",
    "\n",
    "1. For all activities, you are allowed to collaborate with a partner. \n",
    "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
    "\n",
    "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations with regard to how these notebooks will be graded:\n",
    "\n",
    "1. Cells in which \"# YOUR CODE HERE\" is found are the cells where your graded code should be written.\n",
    "2. In order to test out or debug your code you may also create notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\". We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
    "3. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
    "4. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will lose points for your work in that section.\n",
    "5. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
    "6. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the autograder will ignore the modified \"assert\" statement. Make sure you don't edit the assert statements.\n",
    "7. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
    "8. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
    "9. The **Grading** section at the end of the document (before the **Feedback** section) contains some code for our autograder on GradeScope. You are expected to fail this block of code in your Jupyter environment. DO NOT edit this block of code, or you may not get points for your assignment.\n",
    "10. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5bc91cffca4c7fcddc138415994de5d",
     "grade": false,
     "grade_id": "cell-02f2e430dc0f2177",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Deep Learning - Autoencoders\n",
    "\n",
    "In this exercise we'll use an AutoEncoder to learn a dimenionally reduced representation of data and investigate its performance compared to using the original data. You'll learn how to build AutoEncoders and how to use the Keras functional API."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bfa63f9cefeb60ef",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:35.914463Z",
     "start_time": "2024-04-18T18:27:33.785562Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model, Input\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef6a42882991834b",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:36.833618Z",
     "start_time": "2024-04-18T18:27:36.825702Z"
    }
   },
   "source": [
    "data = load_breast_cancer()\n",
    "features = data[\"data\"]\n",
    "targets = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, random_state=0)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:40.520706Z",
     "start_time": "2024-04-18T18:27:40.517356Z"
    }
   },
   "source": [
    "# Read through the description of the data to better understand it\n",
    "# What features do we have and what is the target we're trying to predict?\n",
    "print(data[\"DESCR\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 569\n",
      "\n",
      ":Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      ":Attribute Information:\n",
      "    - radius (mean of distances from center to points on the perimeter)\n",
      "    - texture (standard deviation of gray-scale values)\n",
      "    - perimeter\n",
      "    - area\n",
      "    - smoothness (local variation in radius lengths)\n",
      "    - compactness (perimeter^2 / area - 1.0)\n",
      "    - concavity (severity of concave portions of the contour)\n",
      "    - concave points (number of concave portions of the contour)\n",
      "    - symmetry\n",
      "    - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "    The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "    worst/largest values) of these features were computed for each image,\n",
      "    resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "    10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "    - class:\n",
      "            - WDBC-Malignant\n",
      "            - WDBC-Benign\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "===================================== ====== ======\n",
      "                                        Min    Max\n",
      "===================================== ====== ======\n",
      "radius (mean):                        6.981  28.11\n",
      "texture (mean):                       9.71   39.28\n",
      "perimeter (mean):                     43.79  188.5\n",
      "area (mean):                          143.5  2501.0\n",
      "smoothness (mean):                    0.053  0.163\n",
      "compactness (mean):                   0.019  0.345\n",
      "concavity (mean):                     0.0    0.427\n",
      "concave points (mean):                0.0    0.201\n",
      "symmetry (mean):                      0.106  0.304\n",
      "fractal dimension (mean):             0.05   0.097\n",
      "radius (standard error):              0.112  2.873\n",
      "texture (standard error):             0.36   4.885\n",
      "perimeter (standard error):           0.757  21.98\n",
      "area (standard error):                6.802  542.2\n",
      "smoothness (standard error):          0.002  0.031\n",
      "compactness (standard error):         0.002  0.135\n",
      "concavity (standard error):           0.0    0.396\n",
      "concave points (standard error):      0.0    0.053\n",
      "symmetry (standard error):            0.008  0.079\n",
      "fractal dimension (standard error):   0.001  0.03\n",
      "radius (worst):                       7.93   36.04\n",
      "texture (worst):                      12.02  49.54\n",
      "perimeter (worst):                    50.41  251.2\n",
      "area (worst):                         185.2  4254.0\n",
      "smoothness (worst):                   0.071  0.223\n",
      "compactness (worst):                  0.027  1.058\n",
      "concavity (worst):                    0.0    1.252\n",
      "concave points (worst):               0.0    0.291\n",
      "symmetry (worst):                     0.156  0.664\n",
      "fractal dimension (worst):            0.055  0.208\n",
      "===================================== ====== ======\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      ":Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      ":Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      ":Donor: Nick Street\n",
      "\n",
      ":Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\n",
      "  for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\n",
      "  Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "  San Jose, CA, 1993.\n",
      "- O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\n",
      "  prognosis via linear programming. Operations Research, 43(4), pages 570-577,\n",
      "  July-August 1995.\n",
      "- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "  to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\n",
      "  163-171.\n",
      "\n",
      "|details-end|\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00fdca3096d5954a",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:42.208760Z",
     "start_time": "2024-04-18T18:27:42.204703Z"
    }
   },
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d500a79191103d38",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:42.860847Z",
     "start_time": "2024-04-18T18:27:42.858493Z"
    }
   },
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.185e+01, 1.746e+01, 7.554e+01, ..., 9.140e-02, 3.101e-01,\n",
       "        7.007e-02],\n",
       "       [1.122e+01, 1.986e+01, 7.194e+01, ..., 2.022e-02, 3.292e-01,\n",
       "        6.522e-02],\n",
       "       [2.013e+01, 2.825e+01, 1.312e+02, ..., 1.628e-01, 2.572e-01,\n",
       "        6.637e-02],\n",
       "       ...,\n",
       "       [9.436e+00, 1.832e+01, 5.982e+01, ..., 5.052e-02, 2.454e-01,\n",
       "        8.136e-02],\n",
       "       [9.720e+00, 1.822e+01, 6.073e+01, ..., 0.000e+00, 1.909e-01,\n",
       "        6.559e-02],\n",
       "       [1.151e+01, 2.393e+01, 7.452e+01, ..., 9.653e-02, 2.112e-01,\n",
       "        8.732e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee63a46921cf0ff7",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:43.532904Z",
     "start_time": "2024-04-18T18:27:43.530650Z"
    }
   },
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a91b741d4ee54822",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:27:44.540985Z",
     "start_time": "2024-04-18T18:27:44.537600Z"
    }
   },
   "source": [
    "y_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1dc4a56eec7732bb2329786a6e3f1f5",
     "grade": false,
     "grade_id": "cell-1176b78d06c61ed0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Building a Keras Model with the functional API\n",
    "\n",
    "In this exercise, instead of using the `Sequential` model, we will use the base `Model` in `tf.keras`. There are two approaches to using `tf.keras.Model`. We will use the functional API as outlined in the [`Model` docs](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model).\n",
    "\n",
    "Note that unlike the manner in which we defined our model in the prior Activity, in this Activity (using the base Model) the definition is more like that of the coding of a functional algorithm, e.g.:\n",
    "\n",
    "b = f1(a)  \n",
    "c = f2(b)  \n",
    "d = f3(c)  \n",
    "etc.\n",
    "\n",
    "Unlike traditional script execution in Python, however, those lines of code do not actually execute the computation at that moment. Rather, they are defining a chain of operations that our `Model` will execute later, when we ask it to.\n",
    "\n",
    "### The architecture of your autoencoder\n",
    "\n",
    "Below, you'll build an autoencoder with several layers. Recall that an encoder is composed of an \"encoder\" portion and a \"decoder\" portion. Your encoder will have two layers, transforming the number of features down to 10 in the first layer, and down to 5 (or less) in the second layer. The output of that second layer will serve as the encoded (or \"embedded\") representation, which will later be used as features for an SVM model. Your decoder will also have two layers, undoing the encoding, and transforming the encoded representation up to 10 in the first layer, and up to the original dimensionality in its second layer.\n",
    "\n",
    "Your autoencoder model with thus have 4 layers of neurons. Some would call this a 5-layer model, considering the input samples as a \"layer\" as well, although that is not a layer of neurons."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53b86a7e80ac5f197c5a3e7ae190ec5d",
     "grade": false,
     "grade_id": "cell-b228946b2927aed3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:29:50.716244Z",
     "start_time": "2024-04-18T18:29:50.712956Z"
    }
   },
   "source": [
    "# Determine the number of input dimensions (features) and use that value to\n",
    "# create a tf.keras.Input object, giving it the variable name \"inputs\".\n",
    "#\n",
    "# Also, select a dimension (<=5) for the encoding/embedding (the number of\n",
    "# neurons in the \"middle\" layer of your autoencoder) and give it the\n",
    "# variable name \"embedding_dim\".\n",
    "\n",
    "# YOUR CODE HERE\n",
    "input_dim = X_train.shape[1] \n",
    "inputs = tf.keras.Input(shape=(input_dim,))\n",
    "\n",
    "embedding_dim = 5"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b7026c4683712085ae0617034084db2",
     "grade": true,
     "grade_id": "cell-3cc87f89c7f8bf0f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:29:51.374612Z",
     "start_time": "2024-04-18T18:29:51.372519Z"
    }
   },
   "source": [
    "assert inputs.shape[1] == X_train.shape[1]\n",
    "assert isinstance(embedding_dim, int)\n",
    "assert embedding_dim > 0 and embedding_dim <= 5"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ad2ce2a2cef986ce7a88bb4dc84991b",
     "grade": false,
     "grade_id": "cell-18891b82369b7f2b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:30:23.374769Z",
     "start_time": "2024-04-18T18:30:23.353680Z"
    }
   },
   "source": [
    "# To start, you'll define the encoding portion of the autoencoder.\n",
    "#\n",
    "# Start with \"inputs\" and chain layer calls to two subsequent Dense layers,\n",
    "# the first with 10 neurons (units), the second with \"embedding_dim\" neurons.\n",
    "# See the tf.keras.Model documentation (linked in the instructional cell\n",
    "# above). There is a brief example near the top of that webpage.\n",
    "#\n",
    "# Use ReLU as the activation function for the first Dense layer\n",
    "# and do not set an activation for the second Dense layer.\n",
    "#\n",
    "# Name the output of the second Dense layer \"encoded\".\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "dense_layer1 = Dense(10, activation='relu')(inputs)\n",
    "encoded = Dense(embedding_dim)(dense_layer1)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31abc5cfc4f7c5a5576572024e68b292",
     "grade": true,
     "grade_id": "cell-4bec706b02502c9c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:30:25.633886Z",
     "start_time": "2024-04-18T18:30:25.629103Z"
    }
   },
   "source": [
    "testM = Model(inputs, encoded)\n",
    "assert len(testM.layers) == 3\n",
    "assert encoded.shape[1] == embedding_dim"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "706a2b69ebbb5ef265395058ba85af34",
     "grade": false,
     "grade_id": "cell-4331d11179de97f3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:31:08.798364Z",
     "start_time": "2024-04-18T18:31:08.789209Z"
    }
   },
   "source": [
    "# Now you'll define the decoding portion of the autoencoder.\n",
    "#\n",
    "# Chain layer calls to two more dense layers, the first with 10 neurons and the\n",
    "# second (final layer) with the same number of neurons as your input (number\n",
    "# of features).\n",
    "#\n",
    "# Use ReLU as the activation function for the first new Dense layer\n",
    "# and do not set an activation for the second new Dense layer.\n",
    "#\n",
    "# Name the output of the final Dense layer \"decoded\".\n",
    "\n",
    "# YOUR CODE HERE\n",
    "dense_layer3 = Dense(10, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim)(dense_layer3)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226c9a566578efa0ca1455d7f48e6c19",
     "grade": true,
     "grade_id": "cell-3ea6527c01beb144",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:31:09.390512Z",
     "start_time": "2024-04-18T18:31:09.387634Z"
    }
   },
   "source": [
    "testM = Model(inputs, decoded)\n",
    "print(len(testM.layers))\n",
    "assert len(testM.layers) == 5\n",
    "assert decoded.shape[1] == 30"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the autoencoder\n",
    "\n",
    "Above, you defined the encoder, decoder, and collectively the autoencoder. But we haven't actually instantiated any anything yet.\n",
    "\n",
    "In the cell below, we'll create/instantiate your autoencoder for you, and also create a separate \"encoder\" object which shares its layers with the encoder portion of the autoencoder. This makes it easy for use to train the full autoencoder, and then use just the encoder portion to convert our original features into an embedded representation of lower dimensionality. We'll also create a separate \"decoder\" object in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2205a928bea57abe",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:35:24.174142Z",
     "start_time": "2024-04-18T18:35:24.167936Z"
    }
   },
   "source": [
    "# Create the autoencoder\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "\n",
    "# Create the encoder, which takes the same inputs as the\n",
    "# autoencoder, but stops after the encoding layers. Thus,\n",
    "# the output of the encoder is the encoded representation.\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "\n",
    "# Create the decoder which starts at the encoded output,\n",
    "# and uses the remaining layers of the autoencoder...\n",
    "encoded_embedding = Input(shape=(embedding_dim,))\n",
    "\n",
    "# Get the 1st and 2nd decoder layer from the autoencoder\n",
    "decoder_layer2 = autoencoder.layers[-2]\n",
    "decoder_layer3 = autoencoder.layers[-1]\n",
    "\n",
    "# Chain layer calls\n",
    "decoder_out = decoder_layer3(decoder_layer2(encoded_embedding))\n",
    "\n",
    "# Create the decoder\n",
    "decoder = Model(encoded_embedding, decoder_out)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25699d121c563596",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:31:16.972953Z",
     "start_time": "2024-04-18T18:31:16.964606Z"
    }
   },
   "source": [
    "# View the autoencoder architecture\n",
    "autoencoder.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │           \u001B[38;5;34m310\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)              │            \u001B[38;5;34m55\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │            \u001B[38;5;34m60\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │           \u001B[38;5;34m330\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m755\u001B[0m (2.95 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">755</span> (2.95 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m755\u001B[0m (2.95 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">755</span> (2.95 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:31:17.577136Z",
     "start_time": "2024-04-18T18:31:17.571779Z"
    }
   },
   "source": [
    "# View the encoder architecture\n",
    "encoder.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_7\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │           \u001B[38;5;34m310\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)              │            \u001B[38;5;34m55\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m365\u001B[0m (1.43 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">365</span> (1.43 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m365\u001B[0m (1.43 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">365</span> (1.43 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:32:46.144806Z",
     "start_time": "2024-04-18T18:32:46.137305Z"
    }
   },
   "source": [
    "# View the decoder architecture\n",
    "decoder.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_9\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │            \u001B[38;5;34m60\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │           \u001B[38;5;34m330\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m390\u001B[0m (1.52 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> (1.52 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m390\u001B[0m (1.52 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> (1.52 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Below we'll compile and train the model. __Notice that in our call to `fit` we use `X_train` as both the features and the targets__. Our autoencoder is not a traditional machine learning model. It uses self-supervised learning, in which we want the output to equal the input. This might seem easy, but we are forcing the autoencoder model to compress the features down to a much lower dimensionality, in the bottlenecked autoencoder architecture. Thus, it may have to learn a complex non-linear function to accomplish this task.\n",
    "\n",
    "Note that, as always, we do not use the test set features to train the autoencoder. Test set features are held out for all stages of training including dimensionality reduction.\n",
    "\n",
    "We'll train for quite a while (1000 epochs). If all goes well, you'll see afterwards as to why we train for such a long time."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92f803b5ba04dadd",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:33:13.079613Z",
     "start_time": "2024-04-18T18:33:01.228840Z"
    }
   },
   "source": [
    "# Compile the model, using the Adam optimizer for gradient descent,\n",
    "# and using MSE as the loss function.\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train our model. Note that X_train serves as both features and targets.\n",
    "n_epochs = 1000\n",
    "history = autoencoder.fit(X_train, X_train, epochs=n_epochs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 63062.6484\n",
      "Epoch 2/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 59344.6133\n",
      "Epoch 3/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 57003.7969\n",
      "Epoch 4/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 54837.4414\n",
      "Epoch 5/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 52050.6055\n",
      "Epoch 6/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 48233.3203\n",
      "Epoch 7/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 457us/step - loss: 42980.8750\n",
      "Epoch 8/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 380us/step - loss: 35882.2500\n",
      "Epoch 9/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 26482.3281\n",
      "Epoch 10/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 15860.3057\n",
      "Epoch 11/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309us/step - loss: 7272.9653\n",
      "Epoch 12/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 3074.9719\n",
      "Epoch 13/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 1592.8993\n",
      "Epoch 14/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 365us/step - loss: 949.6671\n",
      "Epoch 15/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 739.1262\n",
      "Epoch 16/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 688.5667\n",
      "Epoch 17/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 678.5768\n",
      "Epoch 18/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 675.4612\n",
      "Epoch 19/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 671.8004\n",
      "Epoch 20/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 366us/step - loss: 667.8723\n",
      "Epoch 21/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 664.0223\n",
      "Epoch 22/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 660.3573\n",
      "Epoch 23/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 656.8398\n",
      "Epoch 24/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 653.4399\n",
      "Epoch 25/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 650.1650\n",
      "Epoch 26/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 647.0020\n",
      "Epoch 27/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 643.9941\n",
      "Epoch 28/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 640.9016\n",
      "Epoch 29/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 636.7348\n",
      "Epoch 30/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 632.1203\n",
      "Epoch 31/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 627.6777\n",
      "Epoch 32/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 623.5211\n",
      "Epoch 33/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 373us/step - loss: 619.0980\n",
      "Epoch 34/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 614.9072\n",
      "Epoch 35/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 611.0131\n",
      "Epoch 36/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 607.5536\n",
      "Epoch 37/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 604.3156\n",
      "Epoch 38/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 601.1324\n",
      "Epoch 39/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 598.0964\n",
      "Epoch 40/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 332us/step - loss: 595.1373\n",
      "Epoch 41/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 592.1615\n",
      "Epoch 42/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 589.0734\n",
      "Epoch 43/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 586.0201\n",
      "Epoch 44/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 582.8983\n",
      "Epoch 45/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 393us/step - loss: 579.8038\n",
      "Epoch 46/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 365us/step - loss: 576.5599\n",
      "Epoch 47/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 572.9493\n",
      "Epoch 48/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 569.5613\n",
      "Epoch 49/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 566.0895\n",
      "Epoch 50/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 367us/step - loss: 562.6873\n",
      "Epoch 51/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374us/step - loss: 559.3414\n",
      "Epoch 52/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 391us/step - loss: 555.9535\n",
      "Epoch 53/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369us/step - loss: 552.5044\n",
      "Epoch 54/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 549.1146\n",
      "Epoch 55/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 378us/step - loss: 545.4216\n",
      "Epoch 56/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 541.1640\n",
      "Epoch 57/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 536.4678\n",
      "Epoch 58/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 381us/step - loss: 531.6218\n",
      "Epoch 59/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 384us/step - loss: 526.6919\n",
      "Epoch 60/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 521.9662\n",
      "Epoch 61/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 517.1766\n",
      "Epoch 62/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 512.2055\n",
      "Epoch 63/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 511.1805\n",
      "Epoch 64/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 501.7898\n",
      "Epoch 65/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 494.9580\n",
      "Epoch 66/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 488.3110\n",
      "Epoch 67/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 481.8242\n",
      "Epoch 68/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 474.2483\n",
      "Epoch 69/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 462.8044\n",
      "Epoch 70/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 436.5790\n",
      "Epoch 71/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 409.5383\n",
      "Epoch 72/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 382.1929\n",
      "Epoch 73/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 351.8682\n",
      "Epoch 74/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 320.6765\n",
      "Epoch 75/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 289.5288\n",
      "Epoch 76/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 260.6613\n",
      "Epoch 77/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 234.7054\n",
      "Epoch 78/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 212.1546\n",
      "Epoch 79/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 193.4244\n",
      "Epoch 80/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 178.4484\n",
      "Epoch 81/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310us/step - loss: 166.7222\n",
      "Epoch 82/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 157.5988\n",
      "Epoch 83/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 150.5730\n",
      "Epoch 84/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 144.8393\n",
      "Epoch 85/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 140.1442\n",
      "Epoch 86/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 136.1762\n",
      "Epoch 87/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 401us/step - loss: 132.8208\n",
      "Epoch 88/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 129.9604\n",
      "Epoch 89/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 416us/step - loss: 127.1710\n",
      "Epoch 90/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 124.7612\n",
      "Epoch 91/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 122.5889\n",
      "Epoch 92/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 120.5889\n",
      "Epoch 93/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 118.7669\n",
      "Epoch 94/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 117.0711\n",
      "Epoch 95/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 115.4908\n",
      "Epoch 96/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 385us/step - loss: 114.0031\n",
      "Epoch 97/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 386us/step - loss: 112.6166\n",
      "Epoch 98/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 393us/step - loss: 111.3335\n",
      "Epoch 99/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 110.1382\n",
      "Epoch 100/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 109.0444\n",
      "Epoch 101/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 108.0252\n",
      "Epoch 102/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 107.0808\n",
      "Epoch 103/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 106.2004\n",
      "Epoch 104/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 105.3680\n",
      "Epoch 105/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 104.5863\n",
      "Epoch 106/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 103.8464\n",
      "Epoch 107/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 103.1378\n",
      "Epoch 108/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 102.6908\n",
      "Epoch 109/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 101.7842\n",
      "Epoch 110/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 101.2882\n",
      "Epoch 111/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369us/step - loss: 100.6596\n",
      "Epoch 112/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 100.1441\n",
      "Epoch 113/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 99.6191\n",
      "Epoch 114/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 99.3021\n",
      "Epoch 115/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 98.6166\n",
      "Epoch 116/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 98.2583\n",
      "Epoch 117/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369us/step - loss: 97.7759\n",
      "Epoch 118/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 97.3911\n",
      "Epoch 119/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 96.9956\n",
      "Epoch 120/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 96.7586\n",
      "Epoch 121/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 96.2249\n",
      "Epoch 122/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 95.9501\n",
      "Epoch 123/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 95.5695\n",
      "Epoch 124/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 95.2668\n",
      "Epoch 125/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 95.0727\n",
      "Epoch 126/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 94.6252\n",
      "Epoch 127/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 94.3969\n",
      "Epoch 128/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 94.0753\n",
      "Epoch 129/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 93.8173\n",
      "Epoch 130/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 93.6515\n",
      "Epoch 131/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 93.2684\n",
      "Epoch 132/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 93.0666\n",
      "Epoch 133/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 92.7857\n",
      "Epoch 134/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 92.6432\n",
      "Epoch 135/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 92.2987\n",
      "Epoch 136/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 92.1061\n",
      "Epoch 137/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 91.8499\n",
      "Epoch 138/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 375us/step - loss: 91.7067\n",
      "Epoch 139/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 91.3924\n",
      "Epoch 140/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 91.2052\n",
      "Epoch 141/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 90.9662\n",
      "Epoch 142/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 90.8167\n",
      "Epoch 143/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 367us/step - loss: 90.5256\n",
      "Epoch 144/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 364us/step - loss: 90.3395\n",
      "Epoch 145/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 90.1122\n",
      "Epoch 146/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 89.9533\n",
      "Epoch 147/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 89.6794\n",
      "Epoch 148/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 89.4908\n",
      "Epoch 149/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 89.3142\n",
      "Epoch 150/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 89.0479\n",
      "Epoch 151/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 88.9184\n",
      "Epoch 152/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 88.6346\n",
      "Epoch 153/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 88.4862\n",
      "Epoch 154/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 88.2624\n",
      "Epoch 155/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 88.0513\n",
      "Epoch 156/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 87.8344\n",
      "Epoch 157/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 87.6198\n",
      "Epoch 158/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 87.4040\n",
      "Epoch 159/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 87.1887\n",
      "Epoch 160/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 86.9723\n",
      "Epoch 161/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 86.7551\n",
      "Epoch 162/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 86.5372\n",
      "Epoch 163/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 86.3182\n",
      "Epoch 164/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 86.0983\n",
      "Epoch 165/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 85.8773\n",
      "Epoch 166/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 85.6551\n",
      "Epoch 167/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 85.4317\n",
      "Epoch 168/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 376us/step - loss: 85.2071\n",
      "Epoch 169/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 84.9812\n",
      "Epoch 170/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 84.7539\n",
      "Epoch 171/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 84.5252\n",
      "Epoch 172/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 84.2950\n",
      "Epoch 173/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 84.0636\n",
      "Epoch 174/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 83.8305\n",
      "Epoch 175/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 83.5958\n",
      "Epoch 176/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 83.3595\n",
      "Epoch 177/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 83.1215\n",
      "Epoch 178/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 82.8820\n",
      "Epoch 179/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 82.6409\n",
      "Epoch 180/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 82.3979\n",
      "Epoch 181/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 82.1531\n",
      "Epoch 182/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 376us/step - loss: 81.9069\n",
      "Epoch 183/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 81.6587\n",
      "Epoch 184/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 81.4087\n",
      "Epoch 185/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 81.1569\n",
      "Epoch 186/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 80.9034\n",
      "Epoch 187/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 80.6481\n",
      "Epoch 188/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 80.3910\n",
      "Epoch 189/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 80.1322\n",
      "Epoch 190/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 79.8713\n",
      "Epoch 191/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 79.6088\n",
      "Epoch 192/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325us/step - loss: 79.3444\n",
      "Epoch 193/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 79.0782\n",
      "Epoch 194/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 78.8102\n",
      "Epoch 195/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 78.5402\n",
      "Epoch 196/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 78.2684\n",
      "Epoch 197/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 77.9948\n",
      "Epoch 198/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 77.7211\n",
      "Epoch 199/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 77.4404\n",
      "Epoch 200/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 77.1710\n",
      "Epoch 201/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 76.8798\n",
      "Epoch 202/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 76.5979\n",
      "Epoch 203/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 76.3153\n",
      "Epoch 204/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 76.0262\n",
      "Epoch 205/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 75.7471\n",
      "Epoch 206/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 75.4472\n",
      "Epoch 207/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 75.1560\n",
      "Epoch 208/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 74.8638\n",
      "Epoch 209/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 74.5658\n",
      "Epoch 210/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 372us/step - loss: 74.2774\n",
      "Epoch 211/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 73.9692\n",
      "Epoch 212/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 73.6683\n",
      "Epoch 213/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 73.3672\n",
      "Epoch 214/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 73.0604\n",
      "Epoch 215/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 72.7624\n",
      "Epoch 216/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 72.4466\n",
      "Epoch 217/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 72.1384\n",
      "Epoch 218/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 71.8233\n",
      "Epoch 219/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 71.5186\n",
      "Epoch 220/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 71.1966\n",
      "Epoch 221/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369us/step - loss: 70.8792\n",
      "Epoch 222/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 70.5622\n",
      "Epoch 223/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 70.2397\n",
      "Epoch 224/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 69.9252\n",
      "Epoch 225/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 69.5963\n",
      "Epoch 226/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 69.2724\n",
      "Epoch 227/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 279us/step - loss: 68.9427\n",
      "Epoch 228/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 68.6215\n",
      "Epoch 229/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 68.2871\n",
      "Epoch 230/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 67.9546\n",
      "Epoch 231/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 67.6241\n",
      "Epoch 232/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 284us/step - loss: 67.2870\n",
      "Epoch 233/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 66.9575\n",
      "Epoch 234/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 66.6169\n",
      "Epoch 235/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 66.2798\n",
      "Epoch 236/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 65.9373\n",
      "Epoch 237/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 65.6018\n",
      "Epoch 238/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 65.2565\n",
      "Epoch 239/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 64.9142\n",
      "Epoch 240/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 64.5671\n",
      "Epoch 241/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325us/step - loss: 64.2263\n",
      "Epoch 242/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 63.8768\n",
      "Epoch 243/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 63.5301\n",
      "Epoch 244/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 63.1789\n",
      "Epoch 245/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 62.8336\n",
      "Epoch 246/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 365us/step - loss: 62.4806\n",
      "Epoch 247/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310us/step - loss: 62.1276\n",
      "Epoch 248/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 61.7783\n",
      "Epoch 249/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 61.4224\n",
      "Epoch 250/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - loss: 61.0726\n",
      "Epoch 251/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 364us/step - loss: 60.7164\n",
      "Epoch 252/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 60.3633\n",
      "Epoch 253/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 60.0052\n",
      "Epoch 254/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 59.6530\n",
      "Epoch 255/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 59.2947\n",
      "Epoch 256/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 58.9368\n",
      "Epoch 257/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 58.5829\n",
      "Epoch 258/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 58.2228\n",
      "Epoch 259/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 57.8688\n",
      "Epoch 260/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 57.5097\n",
      "Epoch 261/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 57.1514\n",
      "Epoch 262/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 56.7972\n",
      "Epoch 263/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 367us/step - loss: 56.4370\n",
      "Epoch 264/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 56.0830\n",
      "Epoch 265/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 55.7247\n",
      "Epoch 266/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 375us/step - loss: 55.3676\n",
      "Epoch 267/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 55.0147\n",
      "Epoch 268/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 54.6561\n",
      "Epoch 269/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 54.3041\n",
      "Epoch 270/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374us/step - loss: 53.9485\n",
      "Epoch 271/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 53.5945\n",
      "Epoch 272/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 53.2415\n",
      "Epoch 273/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 52.8933\n",
      "Epoch 274/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 52.5386\n",
      "Epoch 275/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 52.1917\n",
      "Epoch 276/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 51.8420\n",
      "Epoch 277/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 51.4942\n",
      "Epoch 278/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 51.1477\n",
      "Epoch 279/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 50.8028\n",
      "Epoch 280/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 50.4629\n",
      "Epoch 281/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 50.1164\n",
      "Epoch 282/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 49.7784\n",
      "Epoch 283/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 49.4392\n",
      "Epoch 284/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 288us/step - loss: 49.1017\n",
      "Epoch 285/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 48.7658\n",
      "Epoch 286/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 48.4321\n",
      "Epoch 287/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 48.1003\n",
      "Epoch 288/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 47.7704\n",
      "Epoch 289/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 47.4466\n",
      "Epoch 290/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 47.1150\n",
      "Epoch 291/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 46.7936\n",
      "Epoch 292/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 46.4731\n",
      "Epoch 293/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 46.1549\n",
      "Epoch 294/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 45.8388\n",
      "Epoch 295/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 45.5262\n",
      "Epoch 296/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 45.2170\n",
      "Epoch 297/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 44.9114\n",
      "Epoch 298/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 44.6097\n",
      "Epoch 299/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 44.3122\n",
      "Epoch 300/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325us/step - loss: 44.0191\n",
      "Epoch 301/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 43.7306\n",
      "Epoch 302/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 43.4464\n",
      "Epoch 303/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 43.1664\n",
      "Epoch 304/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 42.8895\n",
      "Epoch 305/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 419us/step - loss: 42.6147\n",
      "Epoch 306/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 289us/step - loss: 42.3402\n",
      "Epoch 307/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 42.0644\n",
      "Epoch 308/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 41.7855\n",
      "Epoch 309/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 41.5032\n",
      "Epoch 310/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 41.2176\n",
      "Epoch 311/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 40.9297\n",
      "Epoch 312/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 40.6411\n",
      "Epoch 313/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 40.3533\n",
      "Epoch 314/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 40.0729\n",
      "Epoch 315/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 39.7831\n",
      "Epoch 316/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 364us/step - loss: 39.5050\n",
      "Epoch 317/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 39.2309\n",
      "Epoch 318/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 38.9596\n",
      "Epoch 319/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 38.6917\n",
      "Epoch 320/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 389us/step - loss: 38.4287\n",
      "Epoch 321/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 38.1743\n",
      "Epoch 322/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 37.9119\n",
      "Epoch 323/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 37.6604\n",
      "Epoch 324/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 37.4129\n",
      "Epoch 325/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 37.1678\n",
      "Epoch 326/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 36.9251\n",
      "Epoch 327/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 391us/step - loss: 36.6866\n",
      "Epoch 328/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 36.4519\n",
      "Epoch 329/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 36.2206\n",
      "Epoch 330/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 35.9925\n",
      "Epoch 331/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 35.7675\n",
      "Epoch 332/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 35.5503\n",
      "Epoch 333/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 35.3245\n",
      "Epoch 334/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 35.1086\n",
      "Epoch 335/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 34.8965\n",
      "Epoch 336/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 34.6856\n",
      "Epoch 337/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 368us/step - loss: 34.4754\n",
      "Epoch 338/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 34.2673\n",
      "Epoch 339/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 34.0616\n",
      "Epoch 340/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 365us/step - loss: 33.8576\n",
      "Epoch 341/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310us/step - loss: 33.6552\n",
      "Epoch 342/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 33.4543\n",
      "Epoch 343/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 33.2553\n",
      "Epoch 344/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 33.0632\n",
      "Epoch 345/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 32.8613\n",
      "Epoch 346/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 32.6687\n",
      "Epoch 347/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 32.4800\n",
      "Epoch 348/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 332us/step - loss: 32.2931\n",
      "Epoch 349/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 32.1077\n",
      "Epoch 350/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 31.9251\n",
      "Epoch 351/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 31.7507\n",
      "Epoch 352/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 31.5679\n",
      "Epoch 353/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 276us/step - loss: 31.3947\n",
      "Epoch 354/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 31.2261\n",
      "Epoch 355/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 31.0600\n",
      "Epoch 356/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 30.8956\n",
      "Epoch 357/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 30.7343\n",
      "Epoch 358/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 30.5763\n",
      "Epoch 359/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 30.4264\n",
      "Epoch 360/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 30.2678\n",
      "Epoch 361/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 30.1185\n",
      "Epoch 362/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 29.9735\n",
      "Epoch 363/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 332us/step - loss: 29.8308\n",
      "Epoch 364/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 29.6897\n",
      "Epoch 365/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 29.5510\n",
      "Epoch 366/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 29.4150\n",
      "Epoch 367/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 29.2865\n",
      "Epoch 368/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 29.1487\n",
      "Epoch 369/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 29.0194\n",
      "Epoch 370/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 28.8934\n",
      "Epoch 371/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 28.7691\n",
      "Epoch 372/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 28.6458\n",
      "Epoch 373/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 372us/step - loss: 28.5239\n",
      "Epoch 374/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 28.4040\n",
      "Epoch 375/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 28.2907\n",
      "Epoch 376/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 28.1674\n",
      "Epoch 377/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 28.0518\n",
      "Epoch 378/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 27.9385\n",
      "Epoch 379/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 27.8267\n",
      "Epoch 380/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 27.7156\n",
      "Epoch 381/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 27.6108\n",
      "Epoch 382/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 276us/step - loss: 27.4964\n",
      "Epoch 383/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 27.3899\n",
      "Epoch 384/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 27.2857\n",
      "Epoch 385/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 27.1836\n",
      "Epoch 386/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 27.0827\n",
      "Epoch 387/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 26.9887\n",
      "Epoch 388/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 26.8855\n",
      "Epoch 389/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 26.7909\n",
      "Epoch 390/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 26.6990\n",
      "Epoch 391/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 366us/step - loss: 26.6096\n",
      "Epoch 392/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 26.5269\n",
      "Epoch 393/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 26.4345\n",
      "Epoch 394/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 26.3509\n",
      "Epoch 395/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 26.2697\n",
      "Epoch 396/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 26.1909\n",
      "Epoch 397/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 26.1184\n",
      "Epoch 398/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 26.0357\n",
      "Epoch 399/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 25.9613\n",
      "Epoch 400/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 25.8886\n",
      "Epoch 401/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 25.8179\n",
      "Epoch 402/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 393us/step - loss: 25.7529\n",
      "Epoch 403/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 25.6769\n",
      "Epoch 404/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 25.6088\n",
      "Epoch 405/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 25.5417\n",
      "Epoch 406/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 25.4763\n",
      "Epoch 407/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 25.4162\n",
      "Epoch 408/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 25.3448\n",
      "Epoch 409/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 25.2811\n",
      "Epoch 410/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 25.2182\n",
      "Epoch 411/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 25.1624\n",
      "Epoch 412/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 25.0953\n",
      "Epoch 413/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 25.0354\n",
      "Epoch 414/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 24.9769\n",
      "Epoch 415/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 24.9212\n",
      "Epoch 416/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369us/step - loss: 24.8719\n",
      "Epoch 417/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - loss: 24.8133\n",
      "Epoch 418/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 24.7639\n",
      "Epoch 419/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 24.7176\n",
      "Epoch 420/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 24.6813\n",
      "Epoch 421/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 278us/step - loss: 24.6371\n",
      "Epoch 422/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 24.6031\n",
      "Epoch 423/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 373us/step - loss: 24.5730\n",
      "Epoch 424/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 286us/step - loss: 24.5531\n",
      "Epoch 425/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 24.5246\n",
      "Epoch 426/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 24.5022\n",
      "Epoch 427/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 24.4765\n",
      "Epoch 428/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 24.4502\n",
      "Epoch 429/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 24.4013\n",
      "Epoch 430/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 24.3438\n",
      "Epoch 431/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 367us/step - loss: 24.2766\n",
      "Epoch 432/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 24.1949\n",
      "Epoch 433/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 24.1189\n",
      "Epoch 434/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 24.0522\n",
      "Epoch 435/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 24.0062\n",
      "Epoch 436/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 23.9885\n",
      "Epoch 437/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 23.9902\n",
      "Epoch 438/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 24.0293\n",
      "Epoch 439/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 24.0992\n",
      "Epoch 440/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 24.1920\n",
      "Epoch 441/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 24.2764\n",
      "Epoch 442/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 24.3044\n",
      "Epoch 443/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 24.2109\n",
      "Epoch 444/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 24.0039\n",
      "Epoch 445/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 366us/step - loss: 23.7830\n",
      "Epoch 446/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 373us/step - loss: 23.6043\n",
      "Epoch 447/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 394us/step - loss: 23.4929\n",
      "Epoch 448/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 23.4369\n",
      "Epoch 449/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 23.4099\n",
      "Epoch 450/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 366us/step - loss: 23.3840\n",
      "Epoch 451/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 23.3695\n",
      "Epoch 452/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 23.3572\n",
      "Epoch 453/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 23.3522\n",
      "Epoch 454/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 23.3377\n",
      "Epoch 455/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 23.3307\n",
      "Epoch 456/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 23.3245\n",
      "Epoch 457/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 23.3198\n",
      "Epoch 458/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 23.3193\n",
      "Epoch 459/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 23.3088\n",
      "Epoch 460/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 23.3039\n",
      "Epoch 461/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 23.2981\n",
      "Epoch 462/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 23.2907\n",
      "Epoch 463/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 23.2850\n",
      "Epoch 464/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 23.2659\n",
      "Epoch 465/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 23.2495\n",
      "Epoch 466/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 23.2303\n",
      "Epoch 467/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 23.2131\n",
      "Epoch 468/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 23.1816\n",
      "Epoch 469/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 276us/step - loss: 23.1538\n",
      "Epoch 470/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 23.1302\n",
      "Epoch 471/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 23.0952\n",
      "Epoch 472/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 23.0653\n",
      "Epoch 473/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 23.0413\n",
      "Epoch 474/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 23.0078\n",
      "Epoch 475/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - loss: 22.9807\n",
      "Epoch 476/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 22.9605\n",
      "Epoch 477/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 22.9318\n",
      "Epoch 478/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 22.9096\n",
      "Epoch 479/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325us/step - loss: 22.8942\n",
      "Epoch 480/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 22.8707\n",
      "Epoch 481/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 22.8533\n",
      "Epoch 482/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 22.8422\n",
      "Epoch 483/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 22.8230\n",
      "Epoch 484/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 22.8091\n",
      "Epoch 485/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 22.7966\n",
      "Epoch 486/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 22.7896\n",
      "Epoch 487/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 22.7730\n",
      "Epoch 488/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 22.7610\n",
      "Epoch 489/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 22.7545\n",
      "Epoch 490/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 22.7387\n",
      "Epoch 491/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 22.7262\n",
      "Epoch 492/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 22.7140\n",
      "Epoch 493/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 22.7059\n",
      "Epoch 494/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 22.6871\n",
      "Epoch 495/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 22.6717\n",
      "Epoch 496/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 22.6614\n",
      "Epoch 497/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 22.6415\n",
      "Epoch 498/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 22.6245\n",
      "Epoch 499/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 22.6126\n",
      "Epoch 500/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 22.5920\n",
      "Epoch 501/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 22.5747\n",
      "Epoch 502/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 22.5631\n",
      "Epoch 503/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 22.5437\n",
      "Epoch 504/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 22.5279\n",
      "Epoch 505/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 22.5184\n",
      "Epoch 506/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 22.5015\n",
      "Epoch 507/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 22.4884\n",
      "Epoch 508/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 22.4818\n",
      "Epoch 509/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 22.4678\n",
      "Epoch 510/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 22.4576\n",
      "Epoch 511/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 22.4538\n",
      "Epoch 512/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 22.4426\n",
      "Epoch 513/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 22.4349\n",
      "Epoch 514/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 275us/step - loss: 22.4337\n",
      "Epoch 515/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 22.4248\n",
      "Epoch 516/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 22.4237\n",
      "Epoch 517/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 22.4162\n",
      "Epoch 518/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 285us/step - loss: 22.4138\n",
      "Epoch 519/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 22.4176\n",
      "Epoch 520/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 22.4139\n",
      "Epoch 521/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 22.4191\n",
      "Epoch 522/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 22.4189\n",
      "Epoch 523/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 22.4282\n",
      "Epoch 524/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 22.4323\n",
      "Epoch 525/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 22.4441\n",
      "Epoch 526/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 22.4499\n",
      "Epoch 527/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 22.4589\n",
      "Epoch 528/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 22.4594\n",
      "Epoch 529/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 22.4464\n",
      "Epoch 530/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 22.4213\n",
      "Epoch 531/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 22.3780\n",
      "Epoch 532/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 22.3142\n",
      "Epoch 533/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 22.2322\n",
      "Epoch 534/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 22.1456\n",
      "Epoch 535/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 276us/step - loss: 22.0607\n",
      "Epoch 536/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 21.9851\n",
      "Epoch 537/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 372us/step - loss: 21.9230\n",
      "Epoch 538/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 21.8811\n",
      "Epoch 539/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 21.8614\n",
      "Epoch 540/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 21.8632\n",
      "Epoch 541/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 21.8935\n",
      "Epoch 542/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 21.9588\n",
      "Epoch 543/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 22.0655\n",
      "Epoch 544/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 22.2150\n",
      "Epoch 545/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 22.4087\n",
      "Epoch 546/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 367us/step - loss: 22.6101\n",
      "Epoch 547/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 22.7675\n",
      "Epoch 548/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 22.7642\n",
      "Epoch 549/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 22.6052\n",
      "Epoch 550/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 22.2947\n",
      "Epoch 551/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 22.0433\n",
      "Epoch 552/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 21.8276\n",
      "Epoch 553/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 21.7321\n",
      "Epoch 554/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 21.6509\n",
      "Epoch 555/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 21.5950\n",
      "Epoch 556/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 21.5646\n",
      "Epoch 557/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 21.5607\n",
      "Epoch 558/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 21.5502\n",
      "Epoch 559/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 21.5498\n",
      "Epoch 560/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 21.5564\n",
      "Epoch 561/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 283us/step - loss: 21.5556\n",
      "Epoch 562/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 21.5569\n",
      "Epoch 563/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 21.5585\n",
      "Epoch 564/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 21.5620\n",
      "Epoch 565/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 21.5541\n",
      "Epoch 566/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 21.5457\n",
      "Epoch 567/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 21.5392\n",
      "Epoch 568/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 378us/step - loss: 21.5209\n",
      "Epoch 569/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 403us/step - loss: 21.5011\n",
      "Epoch 570/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 21.4841\n",
      "Epoch 571/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 21.4565\n",
      "Epoch 572/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 21.4338\n",
      "Epoch 573/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 387us/step - loss: 21.4043\n",
      "Epoch 574/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 21.3782\n",
      "Epoch 575/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 21.3582\n",
      "Epoch 576/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 21.3318\n",
      "Epoch 577/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 21.3097\n",
      "Epoch 578/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 21.2959\n",
      "Epoch 579/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 21.2781\n",
      "Epoch 580/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 21.2655\n",
      "Epoch 581/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 21.2582\n",
      "Epoch 582/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - loss: 21.2600\n",
      "Epoch 583/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 279us/step - loss: 21.2575\n",
      "Epoch 584/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 21.2619\n",
      "Epoch 585/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374us/step - loss: 21.2729\n",
      "Epoch 586/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 21.2932\n",
      "Epoch 587/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 378us/step - loss: 21.3090\n",
      "Epoch 588/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 21.3309\n",
      "Epoch 589/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 21.3583\n",
      "Epoch 590/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 21.3941\n",
      "Epoch 591/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325us/step - loss: 21.4241\n",
      "Epoch 592/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 21.4648\n",
      "Epoch 593/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 287us/step - loss: 21.5036\n",
      "Epoch 594/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 21.5518\n",
      "Epoch 595/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 21.5874\n",
      "Epoch 596/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 21.6123\n",
      "Epoch 597/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 21.5996\n",
      "Epoch 598/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 21.5330\n",
      "Epoch 599/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 21.4186\n",
      "Epoch 600/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 21.2618\n",
      "Epoch 601/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 21.0845\n",
      "Epoch 602/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 20.9134\n",
      "Epoch 603/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 275us/step - loss: 20.7670\n",
      "Epoch 604/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 20.6501\n",
      "Epoch 605/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 20.5594\n",
      "Epoch 606/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 20.4894\n",
      "Epoch 607/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 20.4369\n",
      "Epoch 608/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 20.3960\n",
      "Epoch 609/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 366us/step - loss: 20.3626\n",
      "Epoch 610/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 20.3354\n",
      "Epoch 611/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 20.3151\n",
      "Epoch 612/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 20.2970\n",
      "Epoch 613/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 20.2854\n",
      "Epoch 614/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 20.2815\n",
      "Epoch 615/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 20.2860\n",
      "Epoch 616/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 274us/step - loss: 20.2994\n",
      "Epoch 617/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 20.3238\n",
      "Epoch 618/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 20.3605\n",
      "Epoch 619/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 20.4096\n",
      "Epoch 620/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 20.4694\n",
      "Epoch 621/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 20.5362\n",
      "Epoch 622/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 20.6031\n",
      "Epoch 623/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 20.6603\n",
      "Epoch 624/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 280us/step - loss: 20.6946\n",
      "Epoch 625/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 20.6923\n",
      "Epoch 626/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 20.6484\n",
      "Epoch 627/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 20.5549\n",
      "Epoch 628/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 20.4230\n",
      "Epoch 629/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 20.2885\n",
      "Epoch 630/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 20.1577\n",
      "Epoch 631/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 20.0384\n",
      "Epoch 632/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 19.9410\n",
      "Epoch 633/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 19.8679\n",
      "Epoch 634/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 287us/step - loss: 19.8043\n",
      "Epoch 635/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 19.7562\n",
      "Epoch 636/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 19.7176\n",
      "Epoch 637/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 19.6917\n",
      "Epoch 638/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 19.6812\n",
      "Epoch 639/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 19.6794\n",
      "Epoch 640/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 19.6920\n",
      "Epoch 641/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 19.7229\n",
      "Epoch 642/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 19.7738\n",
      "Epoch 643/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 281us/step - loss: 19.8438\n",
      "Epoch 644/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 19.9321\n",
      "Epoch 645/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 20.0340\n",
      "Epoch 646/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 20.1379\n",
      "Epoch 647/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 20.2272\n",
      "Epoch 648/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 20.2662\n",
      "Epoch 649/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 282us/step - loss: 20.2281\n",
      "Epoch 650/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 20.0993\n",
      "Epoch 651/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 19.9093\n",
      "Epoch 652/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 278us/step - loss: 19.6906\n",
      "Epoch 653/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 19.4837\n",
      "Epoch 654/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 19.3185\n",
      "Epoch 655/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 401us/step - loss: 19.1921\n",
      "Epoch 656/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 19.0959\n",
      "Epoch 657/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 19.0233\n",
      "Epoch 658/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 18.9667\n",
      "Epoch 659/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 377us/step - loss: 18.9208\n",
      "Epoch 660/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 378us/step - loss: 18.8855\n",
      "Epoch 661/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 18.8555\n",
      "Epoch 662/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 18.8350\n",
      "Epoch 663/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 18.8268\n",
      "Epoch 664/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 18.8321\n",
      "Epoch 665/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 286us/step - loss: 18.8529\n",
      "Epoch 666/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 18.8926\n",
      "Epoch 667/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 18.9533\n",
      "Epoch 668/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 19.0340\n",
      "Epoch 669/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 19.1286\n",
      "Epoch 670/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 19.2230\n",
      "Epoch 671/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309us/step - loss: 19.2926\n",
      "Epoch 672/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 332us/step - loss: 19.3058\n",
      "Epoch 673/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 19.2424\n",
      "Epoch 674/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 19.0960\n",
      "Epoch 675/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 18.8974\n",
      "Epoch 676/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 18.7071\n",
      "Epoch 677/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 18.5394\n",
      "Epoch 678/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 383us/step - loss: 18.4122\n",
      "Epoch 679/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 18.3124\n",
      "Epoch 680/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 286us/step - loss: 18.2399\n",
      "Epoch 681/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 18.1834\n",
      "Epoch 682/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 18.1429\n",
      "Epoch 683/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 18.1212\n",
      "Epoch 684/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 18.1106\n",
      "Epoch 685/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - loss: 18.1155\n",
      "Epoch 686/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 18.1403\n",
      "Epoch 687/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 18.1859\n",
      "Epoch 688/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 18.2505\n",
      "Epoch 689/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 18.3316\n",
      "Epoch 690/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 18.4218\n",
      "Epoch 691/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 18.5070\n",
      "Epoch 692/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340us/step - loss: 18.5523\n",
      "Epoch 693/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 18.5396\n",
      "Epoch 694/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 18.4432\n",
      "Epoch 695/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 18.2658\n",
      "Epoch 696/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 18.0528\n",
      "Epoch 697/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 372us/step - loss: 17.8376\n",
      "Epoch 698/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 284us/step - loss: 17.6549\n",
      "Epoch 699/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - loss: 17.5088\n",
      "Epoch 700/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 17.3963\n",
      "Epoch 701/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 363us/step - loss: 17.3102\n",
      "Epoch 702/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 17.2435\n",
      "Epoch 703/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 17.1866\n",
      "Epoch 704/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 17.1403\n",
      "Epoch 705/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 17.1059\n",
      "Epoch 706/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 368us/step - loss: 17.0821\n",
      "Epoch 707/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 17.0700\n",
      "Epoch 708/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 17.0724\n",
      "Epoch 709/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 17.0920\n",
      "Epoch 710/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 17.1302\n",
      "Epoch 711/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 17.1863\n",
      "Epoch 712/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 17.2559\n",
      "Epoch 713/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309us/step - loss: 17.3278\n",
      "Epoch 714/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 17.3820\n",
      "Epoch 715/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 17.3918\n",
      "Epoch 716/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 17.3326\n",
      "Epoch 717/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 17.2036\n",
      "Epoch 718/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 17.0168\n",
      "Epoch 719/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 16.8096\n",
      "Epoch 720/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 369us/step - loss: 16.6305\n",
      "Epoch 721/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309us/step - loss: 16.4795\n",
      "Epoch 722/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 285us/step - loss: 16.3632\n",
      "Epoch 723/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 16.2685\n",
      "Epoch 724/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 356us/step - loss: 16.1927\n",
      "Epoch 725/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330us/step - loss: 16.1366\n",
      "Epoch 726/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 279us/step - loss: 16.0890\n",
      "Epoch 727/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 16.0543\n",
      "Epoch 728/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 16.0360\n",
      "Epoch 729/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 16.0373\n",
      "Epoch 730/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320us/step - loss: 16.0513\n",
      "Epoch 731/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 16.0860\n",
      "Epoch 732/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 277us/step - loss: 16.1434\n",
      "Epoch 733/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 16.2188\n",
      "Epoch 734/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 16.3026\n",
      "Epoch 735/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 16.3784\n",
      "Epoch 736/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 16.4212\n",
      "Epoch 737/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 16.4044\n",
      "Epoch 738/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310us/step - loss: 16.2995\n",
      "Epoch 739/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 16.1090\n",
      "Epoch 740/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 366us/step - loss: 15.8758\n",
      "Epoch 741/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 15.6335\n",
      "Epoch 742/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 15.4197\n",
      "Epoch 743/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 15.2435\n",
      "Epoch 744/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 15.1024\n",
      "Epoch 745/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 14.9898\n",
      "Epoch 746/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - loss: 14.8974\n",
      "Epoch 747/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 14.8161\n",
      "Epoch 748/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 314us/step - loss: 14.7444\n",
      "Epoch 749/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 14.6822\n",
      "Epoch 750/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 14.6276\n",
      "Epoch 751/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 14.5813\n",
      "Epoch 752/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 14.5449\n",
      "Epoch 753/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 14.5208\n",
      "Epoch 754/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 14.5113\n",
      "Epoch 755/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 14.5189\n",
      "Epoch 756/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 14.5453\n",
      "Epoch 757/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 14.5904\n",
      "Epoch 758/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 14.6503\n",
      "Epoch 759/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 14.7153\n",
      "Epoch 760/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 14.7666\n",
      "Epoch 761/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 270us/step - loss: 14.7765\n",
      "Epoch 762/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 14.7154\n",
      "Epoch 763/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 14.5686\n",
      "Epoch 764/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 14.3574\n",
      "Epoch 765/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 14.1131\n",
      "Epoch 766/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 287us/step - loss: 13.8789\n",
      "Epoch 767/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 332us/step - loss: 13.6861\n",
      "Epoch 768/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 367us/step - loss: 13.5366\n",
      "Epoch 769/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 385us/step - loss: 13.4106\n",
      "Epoch 770/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 13.3080\n",
      "Epoch 771/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 13.2189\n",
      "Epoch 772/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 13.1408\n",
      "Epoch 773/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 381us/step - loss: 13.0769\n",
      "Epoch 774/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 13.0197\n",
      "Epoch 775/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 286us/step - loss: 12.9740\n",
      "Epoch 776/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 12.9437\n",
      "Epoch 777/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 12.9294\n",
      "Epoch 778/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 12.9335\n",
      "Epoch 779/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 332us/step - loss: 12.9585\n",
      "Epoch 780/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 274us/step - loss: 13.0054\n",
      "Epoch 781/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 13.0718\n",
      "Epoch 782/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 13.1502\n",
      "Epoch 783/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 13.2246\n",
      "Epoch 784/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 13.2695\n",
      "Epoch 785/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 13.2535\n",
      "Epoch 786/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 288us/step - loss: 13.1543\n",
      "Epoch 787/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 12.9628\n",
      "Epoch 788/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 357us/step - loss: 12.7055\n",
      "Epoch 789/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 282us/step - loss: 12.4342\n",
      "Epoch 790/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 12.1811\n",
      "Epoch 791/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 289us/step - loss: 11.9660\n",
      "Epoch 792/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 11.7916\n",
      "Epoch 793/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 11.6478\n",
      "Epoch 794/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 11.5256\n",
      "Epoch 795/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 285us/step - loss: 11.4193\n",
      "Epoch 796/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 11.3238\n",
      "Epoch 797/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 11.2366\n",
      "Epoch 798/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 11.1556\n",
      "Epoch 799/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 11.0811\n",
      "Epoch 800/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 284us/step - loss: 11.0104\n",
      "Epoch 801/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 10.9460\n",
      "Epoch 802/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 10.8896\n",
      "Epoch 803/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 10.8416\n",
      "Epoch 804/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 10.8034\n",
      "Epoch 805/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 10.7767\n",
      "Epoch 806/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 10.7628\n",
      "Epoch 807/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 10.7623\n",
      "Epoch 808/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 10.7751\n",
      "Epoch 809/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 291us/step - loss: 10.7994\n",
      "Epoch 810/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 10.8317\n",
      "Epoch 811/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 10.8657\n",
      "Epoch 812/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 10.8923\n",
      "Epoch 813/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 10.8981\n",
      "Epoch 814/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 10.8662\n",
      "Epoch 815/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 291us/step - loss: 10.7787\n",
      "Epoch 816/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 10.6240\n",
      "Epoch 817/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 352us/step - loss: 10.4086\n",
      "Epoch 818/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 291us/step - loss: 10.1590\n",
      "Epoch 819/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 317us/step - loss: 9.9132\n",
      "Epoch 820/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 273us/step - loss: 9.6864\n",
      "Epoch 821/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 278us/step - loss: 9.4975\n",
      "Epoch 822/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 373us/step - loss: 9.3384\n",
      "Epoch 823/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 9.2043\n",
      "Epoch 824/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 9.0906\n",
      "Epoch 825/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 8.9874\n",
      "Epoch 826/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 8.8939\n",
      "Epoch 827/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 8.8099\n",
      "Epoch 828/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 348us/step - loss: 8.7298\n",
      "Epoch 829/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 8.6563\n",
      "Epoch 830/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 8.5906\n",
      "Epoch 831/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 276us/step - loss: 8.5323\n",
      "Epoch 832/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 8.4831\n",
      "Epoch 833/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 8.4450\n",
      "Epoch 834/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 8.4198\n",
      "Epoch 835/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 274us/step - loss: 8.4095\n",
      "Epoch 836/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 8.4158\n",
      "Epoch 837/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 267us/step - loss: 8.4397\n",
      "Epoch 838/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 8.4804\n",
      "Epoch 839/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 8.5338\n",
      "Epoch 840/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 286us/step - loss: 8.5906\n",
      "Epoch 841/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 319us/step - loss: 8.6354\n",
      "Epoch 842/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 8.6481\n",
      "Epoch 843/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 8.6105\n",
      "Epoch 844/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 8.5146\n",
      "Epoch 845/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 8.3688\n",
      "Epoch 846/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 8.1942\n",
      "Epoch 847/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323us/step - loss: 8.0140\n",
      "Epoch 848/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 7.8433\n",
      "Epoch 849/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 7.6876\n",
      "Epoch 850/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 288us/step - loss: 7.5429\n",
      "Epoch 851/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 273us/step - loss: 7.4046\n",
      "Epoch 852/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 345us/step - loss: 7.2691\n",
      "Epoch 853/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 7.1370\n",
      "Epoch 854/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - loss: 7.0112\n",
      "Epoch 855/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 333us/step - loss: 6.8900\n",
      "Epoch 856/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 6.7743\n",
      "Epoch 857/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 359us/step - loss: 6.6665\n",
      "Epoch 858/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step - loss: 6.5666\n",
      "Epoch 859/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - loss: 6.4740\n",
      "Epoch 860/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 6.3881\n",
      "Epoch 861/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 281us/step - loss: 6.3084\n",
      "Epoch 862/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 6.2342\n",
      "Epoch 863/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 6.1654\n",
      "Epoch 864/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 374us/step - loss: 6.1011\n",
      "Epoch 865/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312us/step - loss: 6.0417\n",
      "Epoch 866/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 287us/step - loss: 5.9872\n",
      "Epoch 867/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - loss: 5.9376\n",
      "Epoch 868/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 354us/step - loss: 5.8927\n",
      "Epoch 869/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 5.8526\n",
      "Epoch 870/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 5.8170\n",
      "Epoch 871/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 5.7856\n",
      "Epoch 872/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 5.7575\n",
      "Epoch 873/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 280us/step - loss: 5.7318\n",
      "Epoch 874/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 5.7071\n",
      "Epoch 875/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 5.6819\n",
      "Epoch 876/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 5.6547\n",
      "Epoch 877/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - loss: 5.6242\n",
      "Epoch 878/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 285us/step - loss: 5.5891\n",
      "Epoch 879/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 5.5488\n",
      "Epoch 880/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 5.5031\n",
      "Epoch 881/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 5.4522\n",
      "Epoch 882/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 283us/step - loss: 5.3966\n",
      "Epoch 883/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 283us/step - loss: 5.3367\n",
      "Epoch 884/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 5.2731\n",
      "Epoch 885/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 5.2063\n",
      "Epoch 886/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 350us/step - loss: 5.1372\n",
      "Epoch 887/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 287us/step - loss: 5.0670\n",
      "Epoch 888/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 285us/step - loss: 4.9977\n",
      "Epoch 889/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 4.9316\n",
      "Epoch 890/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 4.8713\n",
      "Epoch 891/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 4.8192\n",
      "Epoch 892/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 4.7775\n",
      "Epoch 893/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 4.7483\n",
      "Epoch 894/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 4.7337\n",
      "Epoch 895/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 4.7367\n",
      "Epoch 896/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329us/step - loss: 4.7613\n",
      "Epoch 897/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - loss: 4.8139\n",
      "Epoch 898/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 4.9042\n",
      "Epoch 899/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 337us/step - loss: 5.0457\n",
      "Epoch 900/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 5.2525\n",
      "Epoch 901/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 5.5230\n",
      "Epoch 902/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 5.7927\n",
      "Epoch 903/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309us/step - loss: 5.8837\n",
      "Epoch 904/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 5.6125\n",
      "Epoch 905/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 5.0549\n",
      "Epoch 906/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 4.5074\n",
      "Epoch 907/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 279us/step - loss: 4.1294\n",
      "Epoch 908/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 3.8905\n",
      "Epoch 909/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 3.7509\n",
      "Epoch 910/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 3.6782\n",
      "Epoch 911/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 408us/step - loss: 3.6367\n",
      "Epoch 912/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 370us/step - loss: 3.6071\n",
      "Epoch 913/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304us/step - loss: 3.5839\n",
      "Epoch 914/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 282us/step - loss: 3.5661\n",
      "Epoch 915/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 360us/step - loss: 3.5534\n",
      "Epoch 916/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335us/step - loss: 3.5459\n",
      "Epoch 917/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 3.5442\n",
      "Epoch 918/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347us/step - loss: 3.5485\n",
      "Epoch 919/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 3.5593\n",
      "Epoch 920/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 278us/step - loss: 3.5767\n",
      "Epoch 921/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 364us/step - loss: 3.6006\n",
      "Epoch 922/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 355us/step - loss: 3.6304\n",
      "Epoch 923/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 3.6645\n",
      "Epoch 924/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 278us/step - loss: 3.7003\n",
      "Epoch 925/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 3.7340\n",
      "Epoch 926/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 3.7604\n",
      "Epoch 927/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 3.7736\n",
      "Epoch 928/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351us/step - loss: 3.7681\n",
      "Epoch 929/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 3.7409\n",
      "Epoch 930/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - loss: 3.6920\n",
      "Epoch 931/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341us/step - loss: 3.6258\n",
      "Epoch 932/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 3.5493\n",
      "Epoch 933/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 372us/step - loss: 3.4702\n",
      "Epoch 934/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 361us/step - loss: 3.3946\n",
      "Epoch 935/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 358us/step - loss: 3.3259\n",
      "Epoch 936/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325us/step - loss: 3.2652\n",
      "Epoch 937/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 353us/step - loss: 3.2132\n",
      "Epoch 938/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 3.1702\n",
      "Epoch 939/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310us/step - loss: 3.1361\n",
      "Epoch 940/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309us/step - loss: 3.1105\n",
      "Epoch 941/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 3.0926\n",
      "Epoch 942/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 278us/step - loss: 3.0816\n",
      "Epoch 943/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 3.0771\n",
      "Epoch 944/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 280us/step - loss: 3.0785\n",
      "Epoch 945/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - loss: 3.0856\n",
      "Epoch 946/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 3.0977\n",
      "Epoch 947/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 3.1140\n",
      "Epoch 948/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 3.1331\n",
      "Epoch 949/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 3.1530\n",
      "Epoch 950/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 280us/step - loss: 3.1712\n",
      "Epoch 951/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 289us/step - loss: 3.1851\n",
      "Epoch 952/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 3.1929\n",
      "Epoch 953/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 3.1944\n",
      "Epoch 954/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 3.1905\n",
      "Epoch 955/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 318us/step - loss: 3.1830\n",
      "Epoch 956/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 293us/step - loss: 3.1744\n",
      "Epoch 957/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 281us/step - loss: 3.1676\n",
      "Epoch 958/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 3.1662\n",
      "Epoch 959/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 3.1733\n",
      "Epoch 960/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 3.1921\n",
      "Epoch 961/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321us/step - loss: 3.2224\n",
      "Epoch 962/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 3.2665\n",
      "Epoch 963/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 343us/step - loss: 3.3237\n",
      "Epoch 964/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 3.3759\n",
      "Epoch 965/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342us/step - loss: 3.4181\n",
      "Epoch 966/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 3.4034\n",
      "Epoch 967/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 275us/step - loss: 3.3231\n",
      "Epoch 968/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - loss: 3.1619\n",
      "Epoch 969/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334us/step - loss: 2.9549\n",
      "Epoch 970/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - loss: 2.7571\n",
      "Epoch 971/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 2.6069\n",
      "Epoch 972/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322us/step - loss: 2.5120\n",
      "Epoch 973/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - loss: 2.4611\n",
      "Epoch 974/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 2.4396\n",
      "Epoch 975/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 339us/step - loss: 2.4374\n",
      "Epoch 976/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346us/step - loss: 2.4500\n",
      "Epoch 977/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 2.4760\n",
      "Epoch 978/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 274us/step - loss: 2.5166\n",
      "Epoch 979/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 2.5737\n",
      "Epoch 980/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 2.6499\n",
      "Epoch 981/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 2.7451\n",
      "Epoch 982/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310us/step - loss: 2.8527\n",
      "Epoch 983/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 2.9546\n",
      "Epoch 984/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 3.0203\n",
      "Epoch 985/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328us/step - loss: 3.0189\n",
      "Epoch 986/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 336us/step - loss: 2.9420\n",
      "Epoch 987/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326us/step - loss: 2.8165\n",
      "Epoch 988/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 275us/step - loss: 2.6860\n",
      "Epoch 989/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 279us/step - loss: 2.5817\n",
      "Epoch 990/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324us/step - loss: 2.5126\n",
      "Epoch 991/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 2.4750\n",
      "Epoch 992/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313us/step - loss: 2.4632\n",
      "Epoch 993/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315us/step - loss: 2.4728\n",
      "Epoch 994/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307us/step - loss: 2.5013\n",
      "Epoch 995/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331us/step - loss: 2.5482\n",
      "Epoch 996/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 338us/step - loss: 2.6137\n",
      "Epoch 997/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327us/step - loss: 2.6979\n",
      "Epoch 998/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 2.7987\n",
      "Epoch 999/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - loss: 2.9086\n",
      "Epoch 1000/1000\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311us/step - loss: 3.0111\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:33:18.408699Z",
     "start_time": "2024-04-18T18:33:18.078039Z"
    }
   },
   "source": [
    "# Let's look at our the loss scores collected during the training/fit session above.\n",
    "\n",
    "plt.semilogy(np.arange(1, n_epochs+1), history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss during training session.')\n",
    "\n",
    "print(f\"Loss on the final training epoch was {history.history['loss'][-1]:0.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on the final training epoch was 2.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training convergence\n",
    "\n",
    "If everthing went as planned, you'll see a somewhat chaotic, stairstep-shapped loss curve in the figure above. During training, the model parameters sometimes got stuck in or a near a local minimum of the loss function, which is why you see some flatter portions even during the early training epochs. Fortunately the learning procedure found a way out of those local minima.\n",
    "\n",
    "### Embedding\n",
    "\n",
    "Now that you've trained the autoencoder, and given yourself direct access to the encoder half of the autoencoder, we'll use that encoder (below) to \"embed\" the original features into a new feature/embedding space. The resulting new features are typically called \"embedded\" or \"encoded\" features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf4fdda42d853412",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:33:52.379091Z",
     "start_time": "2024-04-18T18:33:52.300225Z"
    }
   },
   "source": [
    "# Calculate the embedded features using the encoder model\n",
    "X_train_embed = encoder.predict(X_train)\n",
    "X_test_embed = encoder.predict(X_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 890us/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 432us/step\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Now comes the actual training of a supervised learning model. We have our embedded features, thanks to our autoencoder, along with our original features.\n",
    "\n",
    "__You'll train two SVM models to predict breast cancer diagnoses: malignant or benign.__  \n",
    "One SVM will use the original features and one will use the embedded features.  \n",
    "Which do you think well make better test set predictions?\n",
    "\n",
    "You may experience some `ConvergenceWarning` messages. That's okay, you can ignore them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56c7035cf4e5032e5bbbb1ce9d7d4d35",
     "grade": false,
     "grade_id": "cell-740d35aaf5aced68",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:35:31.650508Z",
     "start_time": "2024-04-18T18:35:31.577832Z"
    }
   },
   "source": [
    "# Train two LinearSVC models\n",
    "#\n",
    "# Create and fit a model with the original features.\n",
    "# Name the model \"base_model\".\n",
    "#\n",
    "# Create and fit a model with autoencoder-embedded features.\n",
    "# Name the model \"embed_model\".\n",
    "#\n",
    "# When you create your LinearSVC models, you may want to\n",
    "# set random_seed to the same values (e.g., 0) for both models\n",
    "# for a more apples-to-apples comparison.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "encoder = tf.keras.Model(inputs=inputs, outputs=encoded)\n",
    "\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "\n",
    "base_model = LinearSVC(random_state=0)\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "embed_model = LinearSVC(random_state=0)\n",
    "embed_model.fit(X_train_encoded, y_train)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 825us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benfunk/DataspellProjects/Machine-Learning/venv/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/benfunk/DataspellProjects/Machine-Learning/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/benfunk/DataspellProjects/Machine-Learning/venv/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/benfunk/DataspellProjects/Machine-Learning/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=0)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(random_state=0)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00d0db0002d2e5bce8165b07daf5879a",
     "grade": true,
     "grade_id": "cell-fcb552f3048b39de",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:35:35.067525Z",
     "start_time": "2024-04-18T18:35:35.065224Z"
    }
   },
   "source": [
    "assert base_model\n",
    "assert isinstance(base_model, LinearSVC)\n",
    "assert base_model.coef_.shape[1] == 30\n",
    "assert embed_model\n",
    "assert isinstance(embed_model, LinearSVC)\n",
    "assert embed_model.coef_.shape[1] == embedding_dim"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4569d596e6d9513",
     "locked": false,
     "schema_version": 3,
     "solution": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-18T18:35:36.617585Z",
     "start_time": "2024-04-18T18:35:36.613914Z"
    }
   },
   "source": [
    "print(f\"The base SVM accuracy score:                  {base_model.score(X_test, y_test):0.3f}\")\n",
    "print(f\"The autoencoder embedding SVM accuracy score: {embed_model.score(X_test_embed, y_test):0.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base SVM accuracy score:                  0.902\n",
      "The autoencoder embedding SVM accuracy score: 0.937\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parting thoughts\n",
    "\n",
    "Was the test set score of the embedded data model better or worse than that of the original data model?\n",
    "\n",
    "Ask youself why it might be better or worse. \n",
    "\n",
    " - What happens when you change the activation function(s) in the autoencoder?\n",
    " - What happens when you change the embedding_dim to be larger or smaller?\n",
    " - Is it sufficient to just use LinearSVC with the default parameters to make any of these conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "The following code block is purely used for grading. If you find any error, you can ignore. DO NOT MODIFY THE CODE BLOCK BELOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograding with Otter Grader\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f548879bd197ac235bc863b352b6483",
     "grade": false,
     "grade_id": "cell-1095f38e46bb02b4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return 'it was interesting seeing how the autoencoder works'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
     "grade": true,
     "grade_id": "feedback-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
